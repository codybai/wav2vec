activation_dropout: 0.1
adam_betas: '(0.9,0.98)'
adam_eps: 1e-08
all_gather_list_size: 16384
apply_mask: True
arch: 'wav2vec_ctc'
attention_dropout: 0.0
best_checkpoint_metric: 'wer'
bf16: False
bpe: None
broadcast_buffers: False
bucket_cap_mb: 25
checkpoint_suffix: ''
clip_norm: 0.0
cpu: False
criterion: 'ctc'
curriculum: 0
data: 'data'
data_buffer_size: 10
dataset_impl: None
ddp_backend: 'no_c10d'
decay_steps: 40000
device_id: 0
disable_validation: False
distributed_backend: 'nccl'
distributed_init_method: None
distributed_no_spawn: False
distributed_port: -1
distributed_rank: 0
distributed_world_size: 1
distributed_wrapper: 'DDP'
dropout: 0.0
dropout_input: 0
empty_cache_freq: 0
enable_padding: False
fast_stat_sync: False
feature_grad_mult: 0.0
final_dropout: 0.0
final_lr_scale: 0.05
find_unused_parameters: False
finetune_from_model: None
fix_batches_to_gpus: False
fixed_validation_seed: None
fp16: True
fp16_init_scale: 128
fp16_no_flatten_grads: False
fp16_scale_tolerance: 0.0
fp16_scale_window: None
freeze_finetune_updates: 10000
hold_steps: 32000
init_lr_scale: 0.01
keep_best_checkpoints: -1
keep_interval_updates: -1
keep_last_epochs: -1
labels: 'ltr'
layerdrop: 0.1
localsgd_frequency: 3
log_format: 'simple'
log_interval: 10
lr: [2e-05]
lr_scheduler: 'tri_stage'
mask_channel_length: 64
mask_channel_other: 0.0
mask_channel_prob: 0.5
mask_channel_selection: 'static'
mask_length: 10
mask_other: 0.0
mask_prob: 0.5
mask_selection: 'static'
max_epoch: 0
max_sample_size: None
max_sentences: None
max_sentences_valid: None
max_tokens: 1280000
max_tokens_valid: 1280000
max_update: 80000
maximize_best_checkpoint_metric: False
memory_efficient_bf16: False
memory_efficient_fp16: False
min_loss_scale: 0.0001
min_lr: -1
min_sample_size: None
model_parallel_size: 1
no_epoch_checkpoints: True
no_last_checkpoints: False
no_mask_channel_overlap: False
no_mask_overlap: False
no_pretrained_weights: False
no_progress_bar: False
no_save: False
no_save_optimizer_state: False
no_seed_provided: False
normalize: False
nprocs_per_node: 1
num_workers: 4
optimizer: 'adam'
optimizer_overrides: '{}'
patience: -1
profile: False
quantization_config_path: None
remove_bpe: 'letter'
required_batch_size_multiple: 8
reset_dataloader: False
reset_lr_scheduler: False
reset_meters: False
reset_optimizer: False
restore_file: 'checkpoint_last.pt'
sample_rate: 16000
save_dir: 'data'
save_interval: 1
save_interval_updates: 0
seed: 2337
sentence_avg: True
skip_invalid_size_inputs_valid_test: False
slowmo_algorithm: 'LocalSGD'
slowmo_momentum: None
stop_time_hours: 0
task: 'audio_pretraining'
tensorboard_logdir: ''
threshold_loss_scale: None
tokenizer: None
tpu: False
train_subset: 'train'
update_freq: [3]
use_bmuf: False
use_old_adam: False
user_dir: None
valid_subset: 'valid'
validate_after_updates: 10000
validate_interval: 100
validate_interval_updates: 0
w2v_path: 'data/wav2vec_small_960h.pt'
warmup_steps: 8000
weight_decay: 0.0
wer_args: '("data/4-gram.bin","data/lexicon.txt",2,-1)'
zero_infinity: True
